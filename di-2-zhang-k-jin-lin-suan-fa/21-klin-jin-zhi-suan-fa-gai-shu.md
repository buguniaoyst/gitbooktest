# k-近邻算法概述

简单地说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。

---

```
                                           k-近邻值算法

优点：精度高，对异常值不敏感，无数据输入假定。

缺点：计算复杂度高，空间复杂度高。

使用数据范围：数值型和标称型。
```

---

本书讲解的第一个机器学习算法是k-近邻算法（kNN），它的工作原理是：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都在在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。

现在我们回到前面电影分类的例子，使用k-近邻算法分类爱情片和动作片。有人曾经统计过很多电影的打斗镜头和接吻镜头，图2-1显示了6部电影的打斗和接吻镜头数。加入有一部未看过的电影，如何确定他是爱情片还是动作片呢？我们可以使用kNN来解决这个问题。

![](/assets/电影分类.png)

首先我们需要知道这个未知电影存在多少个打斗镜头，图2-1中问号未知是该未知电影出现的镜头数图形化展示，具体数字参见表2-1.

![](/assets/电影镜头数统计.png)

即使不知道未知电影属于哪种类型，我们也可以通过某种方法计算出来。首先计算未知电影与样本集中其他电影的距离，如图2-2所示。此时暂时不关心如何计算得到这些距离值，使用Python实现电影分类应用时，会提供具体的计算方法。

![](/assets/已知电影和未知电影的距离.png)

现在我们得到了样本集中所有电影与未知电影的距离，按照距离递增排序，可以找到k个距离最近的距离。假定k=3，则三个最靠近的电影一次是He's Not Really into Dudes,Beautiful Woman 和 California Man。k-近邻算法按照距离最近的三部电影的类型，决定未知电影的类型，而这三部电影全部是爱情片，因此我们判定未知电影是爱情片。

本章主要讲解如何在实际环境中应用k-近邻算法，同时设计如何使用Python工具和相关的机器学习属于。按照1.5节开发机器学习应用的通用步骤，我们使用Python语言开发k-近邻算法的简单应用，以检验算法使用的正确性。

```
k-近邻算法的一般流程

（1）收集数据：可以使用任何方法。

（2）准备数据：距离计算所需要的数值，最好是结构化的数据格式。

（3）分析数据：可以使用任何方法。

（4）训练算法：此步骤不适用与k-近邻算法。

（5）测试算法：计算错误率。

（6）使用算法：首先需要输入样本数据和结构化的输出结构，然后运行k-近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理。
```
















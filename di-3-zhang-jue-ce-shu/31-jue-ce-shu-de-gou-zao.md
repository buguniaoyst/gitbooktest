# 决策树的构造

决策树：

有点：计算复杂度不高，输出结果已于理解，对中间值的缺失不敏感，可以处理不相关特征数据。

缺点：可能会产生过渡匹配的问题。

适用数据类型：数值型和标称型。

本节将一步步地构造决策树算法，并会涉及许多有趣的细节。首先我们讨论数学上如何使用信息论划分数据集，然后编写代码将理论应用到具体的数据集上，最后编写代码构建决策树。

在构造决策树时，我们需要解决的第一个问题就是，当前数据及上哪个特征在划分数据分类时起决定性作用。为了找到决定性的特征，划分出最好的结果，我们必须评估每个特征。完成测试之后，原始数据集就被划分为几个数据子集。这些数据子集会分布在第一个决策点的所有分支上。如果某个分支下的数据属于同一类型，则当前无需月度的垃圾邮件已经正确地划分数据分类，无需进一步对数据集进行分割。如果数据子集内的数据不属于同一类型，则需要重复划分数据子集的过程。如何划分数据子集的算法和划分原始数据集的方法相同，知道所有具有相同类型的数据均在一个数据子集内。

创建分支的伪代码函数createBranch\(\)如下所示：

检测数据集中每个子项是否属于同一分类：

```
If so return 类标签；
Else
   寻找划分数据集的最好特征
    划分数据集
    创建分支节点
       for每个划分的子集
           调用函数createBranch并增加返回结果到分支节点中
     return 分支节点
```

上面的伪代码createBranch是一个递归函数，在倒数第二行直接调用了它自己。后面我们将上面的伪代码转换为Python代码，这里我们需要进一步了解算法是如何划分数据集的。

```
                                            决策树的一般流程
（1）收集数据：可以使用任何方法。
（2）准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。
（3）分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。
（4）训练数据：构造书的数据结构。
（5）测试算法：使用经验树计算错误率。
（6）使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好滴理解数据的内在含义。
```

一些决策树算法采用二分法划分数据，本书并不采用这种方法。如果依据某个属性划分数据将会产生4个可能的值，我们将把数据划分为四块，并创建四个不同的分支。本书使用ID3算法划分数据集，该算法处理如何划分数据集，何时停止划分数据集（进一步的信息可以参见[http://en.wikipedia.org/wiki/ID3\_algorithm ](http://en.wikipedia.org/wiki/ID3_algorithm）每次划分数据集时我们只选取一个特征属性，如果训练集中存在20个特征，第一次我们选择哪个特征作为划分的参考属性呢？)）[每次划分数据集时我们只选取一个特征属性，如果训练集中存在20个特征，第一次我们选择哪个特征作为划分的参考属性呢？](http://en.wikipedia.org/wiki/ID3_algorithm）每次划分数据集时我们只选取一个特征属性，如果训练集中存在20个特征，第一次我们选择哪个特征作为划分的参考属性呢？)

表3-1的数据包含5个海洋动物，特征包括：不浮出水面是否可以生存，以及是否有脚蹼。我们可以将这些动物分为两类：鱼和非鱼类。现在我们想要决定依据第一个特征还是第二个特征划分数据。在回答这个问题之前，我们必须采用量化的方法判断如何划分数据。下一小节将详细讨论这个问题。

表3-1 海洋生物数据

|  | 不浮出水面是否可以生存 | 是否有脚蹼 | 属于鱼类 |
| :--- | :--- | :--- | :--- |
| 1 | 是 | 是 | 是 |
| 2 | 是 | 是 | 是 |
| 3 | 是 | 否 | 否 |
| 4 | 否 | 是 | 否 |
| 5 | 否 | 是 | 否 |









